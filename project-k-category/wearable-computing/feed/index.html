<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Wearable Computing &#8211; Department of Computer Engineering</title>
	<atom:link href="http://www.ce.pdn.ac.lk/project-k-category/wearable-computing/feed/" rel="self" type="application/rss+xml" />
	<link>http://www.ce.pdn.ac.lk</link>
	<description>University of Peradeniya</description>
	<lastBuildDate>Mon, 10 Jun 2019 06:14:35 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.2.1</generator>

<image>
	<url>http://www.ce.pdn.ac.lk/wp-content/uploads/2019/05/cropped-University_of_Peradeniya_crest-32x32.png</url>
	<title>Wearable Computing &#8211; Department of Computer Engineering</title>
	<link>http://www.ce.pdn.ac.lk</link>
	<width>32</width>
	<height>32</height>
</image> 
	<item>
		<title>Biofeedback inputs for first person shooter games</title>
		<link>http://www.ce.pdn.ac.lk/project/biofeedback-inputs-for-first-person-shooter-games/</link>
				<pubDate>Mon, 10 Jun 2019 06:14:04 +0000</pubDate>
		<dc:creator><![CDATA[webmaster]]></dc:creator>
		
		<guid isPermaLink="false">http://192.248.42.20/?post_type=post-k-project&#038;p=392894</guid>
				<description><![CDATA[&#8205;]]></description>
								<content:encoded><![CDATA[<h5>Team Members</h5>
<ul>
<li style="list-style-type: none;">
<ul>
<li>
<h6><span style="font-weight: 400;">Sanjeewa Kumara</span></h6>
</li>
<li>
<h6><span style="font-weight: 400;">Chamini Prashakthi</span></h6>
</li>
<li>
<h6><span style="font-weight: 400;">Sasitha Rajapaksha</span></h6>
</li>
<li>
<h6><span style="font-weight: 400;">Titus Nandakumara</span></h6>
</li>
</ul>
</li>
</ul>
<h6><span style="font-weight: 400;">In this paper, we examine how the Biofeedback can be used to improve user experience while playing the first person shooter game. Biofeedback is used to feed the body information of a real person to the game. Therefore, we are going to control and enhance a FPS game using some physiological functions of a human by mapping with the game character. We demonstrate the concept through a simple video game using two sensors to</span></h6>
<h6><span style="font-weight: 400;">detect the physiological states of the real player. Those two sensor devices are called as OpenBCI, which catches the Electrocardiography (ECG) signal and the Electrooculography (EOG) signal and Galvanic skin response sensor, which capture the skin conductance. Using these measurements, we can check the player&#8217;s excitement, eye movement, and the tiredness at the moment. If the excitement level become higher and the tiredness</span></h6>
<h6><span style="font-weight: 400;">become lower, the speed of the player will be increase, targeting for an aim will be high and generating enemies per time will be increase. If the excitement level became lower and the tiredness become higher, all the previous results will be happen in opposite way. If player looks left side, the screen will rotate left side by 15 degrees and for right side screen will rotate right side by 15 degrees. The major aim of this project is leads players to feel as real life experience while playing. Moreover, the game become addictive when it has this kind of features. In addition, another goal of adding this feature to the game is to control our body ourselves.</span></h6>
]]></content:encoded>
										</item>
		<item>
		<title>Emotion based safety measures for drivers</title>
		<link>http://www.ce.pdn.ac.lk/project/emotion-based-safety-measures-for-drivers/</link>
				<pubDate>Mon, 10 Jun 2019 06:02:52 +0000</pubDate>
		<dc:creator><![CDATA[webmaster]]></dc:creator>
		
		<guid isPermaLink="false">http://192.248.42.20/?post_type=post-k-project&#038;p=392891</guid>
				<description><![CDATA[&#8205;]]></description>
								<content:encoded><![CDATA[<h5>Team Members</h5>
<ul>
<li style="list-style-type: none;">
<ul>
<li>
<h6><span style="font-weight: 400;">Vimukthi Perera</span></h6>
</li>
<li>
<h6><span style="font-weight: 400;">Ching Shi</span></h6>
</li>
<li>
<h6><span style="font-weight: 400;">Brian Udugama</span></h6>
</li>
<li>
<h6><span style="font-weight: 400;">Titus Nanda Kumara</span></h6>
</li>
</ul>
</li>
</ul>
<h6><span style="font-weight: 400;">A major research focus in automobile development is improvement of safety. The main cause for road accidents is the distractions to the driver. Most distractions are in the form of emotional changes that result in unfitting states of mind. Existing methods of detecting a sleepy driver using image processing are proven to be challenging in practice due to the variations in the lighting condition. Further, it is insufficient to detect sleepiness</span></h6>
<h6><span style="font-weight: 400;">and fatigue as there are several other emotional conditions which could cause a driver to be in an unfitting state for driving. Such states of the driver could be identified using basic parameters of an ECG. In this research, different patterns in the ECG of the driver and patterns in the motion of the vehicle were identified for each emotional state to predict the driverâ€™s emotional condition and warn if it tends to unsafe driving. Patterns in the</span></h6>
<h6><span style="font-weight: 400;">motion of the vehicle were analyzed in terms of the vehicle speed and the change in the acceleration. A Heart and Brain SpikerShield was used to obtain the ECG of the driver and an MPU-6050 IMU was used to gather the acceleration data of the vehicle. Collected data is sent to an Android device via Bluetooth for further processing. We were able to recognize the changes in the ECG and the driving pattern of a drowsy driver and an</span></h6>
<h6><span style="font-weight: 400;">aggressive driver. Accuracy of the emotion detection was verified by comparing the results against known methods.</span></h6>
]]></content:encoded>
										</item>
	</channel>
</rss>
